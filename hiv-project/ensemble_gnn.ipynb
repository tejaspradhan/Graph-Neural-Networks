{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble_gnn",
      "provenance": [],
      "authorship_tag": "ABX9TyOoZTqIcwf81Rm5rslWuW5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaspradhan/Graph-Neural-Networks/blob/main/hiv-project/ensemble_gnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJNCngRtQqNx",
        "outputId": "571a0c25-515c-4afd-a2d9-83844dff31a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Install rdkit\n",
        "import sys\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "import shutil\n",
        "from logging import getLogger, StreamHandler, INFO\n",
        " \n",
        " \n",
        "logger = getLogger(__name__)\n",
        "logger.addHandler(StreamHandler())\n",
        "logger.setLevel(INFO)\n",
        " \n",
        " \n",
        "def install(\n",
        "        chunk_size=4096,\n",
        "        file_name=\"Miniconda3-latest-Linux-x86_64.sh\",\n",
        "        url_base=\"https://repo.continuum.io/miniconda/\",\n",
        "        conda_path=os.path.expanduser(os.path.join(\"~\", \"miniconda\")),\n",
        "        rdkit_version=None,\n",
        "        add_python_path=True,\n",
        "        force=False):\n",
        "    \"\"\"install rdkit from miniconda\n",
        "    ```\n",
        "    import rdkit_installer\n",
        "    rdkit_installer.install()\n",
        "    ```\n",
        "    \"\"\"\n",
        " \n",
        "    python_path = os.path.join(\n",
        "        conda_path,\n",
        "        \"lib\",\n",
        "        \"python{0}.{1}\".format(*sys.version_info),\n",
        "        \"site-packages\",\n",
        "    )\n",
        " \n",
        "    if add_python_path and python_path not in sys.path:\n",
        "        logger.info(\"add {} to PYTHONPATH\".format(python_path))\n",
        "        sys.path.append(python_path)\n",
        " \n",
        "    if os.path.isdir(os.path.join(python_path, \"rdkit\")):\n",
        "        logger.info(\"rdkit is already installed\")\n",
        "        if not force:\n",
        "            return\n",
        " \n",
        "        logger.info(\"force re-install\")\n",
        " \n",
        "    url = url_base + file_name\n",
        "    python_version = \"{0}.{1}.{2}\".format(*sys.version_info)\n",
        " \n",
        "    logger.info(\"python version: {}\".format(python_version))\n",
        " \n",
        "    if os.path.isdir(conda_path):\n",
        "        logger.warning(\"remove current miniconda\")\n",
        "        shutil.rmtree(conda_path)\n",
        "    elif os.path.isfile(conda_path):\n",
        "        logger.warning(\"remove {}\".format(conda_path))\n",
        "        os.remove(conda_path)\n",
        " \n",
        "    logger.info('fetching installer from {}'.format(url))\n",
        "    res = requests.get(url, stream=True)\n",
        "    res.raise_for_status()\n",
        "    with open(file_name, 'wb') as f:\n",
        "        for chunk in res.iter_content(chunk_size):\n",
        "            f.write(chunk)\n",
        "    logger.info('done')\n",
        " \n",
        "    logger.info('installing miniconda to {}'.format(conda_path))\n",
        "    subprocess.check_call([\"bash\", file_name, \"-b\", \"-p\", conda_path])\n",
        "    logger.info('done')\n",
        " \n",
        "    logger.info(\"installing rdkit\")\n",
        "    subprocess.check_call([\n",
        "        os.path.join(conda_path, \"bin\", \"conda\"),\n",
        "        \"install\",\n",
        "        \"--yes\",\n",
        "        \"-c\", \"rdkit\",\n",
        "        \"python==3.7.3\",\n",
        "        \"rdkit\" if rdkit_version is None else \"rdkit=={}\".format(rdkit_version)])\n",
        "    logger.info(\"done\")\n",
        " \n",
        "    import rdkit\n",
        "    logger.info(\"rdkit-{} installation finished!\".format(rdkit.__version__))\n",
        " \n",
        " \n",
        "if __name__ == \"__main__\":\n",
        "    install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHVD0K4bQw0Y",
        "outputId": "3a5e8956-5279-4fa3-cd50-42df1710a51e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "add /root/miniconda/lib/python3.7/site-packages to PYTHONPATH\n",
            "python version: 3.7.12\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit\n",
            "done\n",
            "rdkit-2020.09.1 installation finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "! pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "! pip install -q torch-cluster -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "! pip install -q torch-geometric"
      ],
      "metadata": {
        "id": "QQrpkHW2Qzxi",
        "outputId": "b3d56155-097d-4e27-ab95-79d537a6bcaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 370 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 482 kB 45.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 462 kB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch \n",
        "import torch.nn.functional as F \n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset, Data\n",
        "from torch_geometric.nn import GATConv, Linear, TopKPooling\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "from torch_geometric.loader import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.nn import GCNConv"
      ],
      "metadata": {
        "id": "L6rI4HeJQ_hW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HIVDataset(Dataset):\n",
        "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
        "        \"\"\"\n",
        "        root = Where the dataset should be stored. This folder is split\n",
        "        into raw_dir (downloaded dataset) and processed_dir (processed data). \n",
        "        \"\"\"\n",
        "        self.test = test\n",
        "        self.filename = filename\n",
        "        super(HIVDataset, self).__init__(root, transform, pre_transform)\n",
        "        \n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
        "            (The download func. is not implemented here)  \n",
        "        \"\"\"\n",
        "        return self.filename\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'not_implemented.pt'\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        self.data = pd.read_csv(self.raw_paths[0])\n",
        "        print(self.raw_paths)\n",
        "        for index, mol in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
        "            mol_obj = Chem.MolFromSmiles(mol[\"smiles\"])\n",
        "            # Get node features\n",
        "            node_feats = self._get_node_features(mol_obj)\n",
        "            # Get edge features\n",
        "            edge_feats = self._get_edge_features(mol_obj)\n",
        "            # Get adjacency info\n",
        "            edge_index = self._get_adjacency_info(mol_obj)\n",
        "            # Get labels info\n",
        "            label = self._get_labels(mol[\"HIV_active\"])\n",
        "\n",
        "            # Create data object\n",
        "            data = Data(x=node_feats, \n",
        "                        edge_index=edge_index,\n",
        "                        edge_attr=edge_feats,\n",
        "                        y=label,\n",
        "                        smiles=mol[\"smiles\"]\n",
        "                        ) \n",
        "            if self.test:\n",
        "                torch.save(data, \n",
        "                    os.path.join(self.processed_dir, \n",
        "                                 f'data_test_{index}.pt'))\n",
        "            else:\n",
        "                torch.save(data, \n",
        "                    os.path.join(self.processed_dir, \n",
        "                                 f'data_{index}.pt'))\n",
        "\n",
        "    def _get_node_features(self, mol):\n",
        "        \"\"\" \n",
        "        This will return a matrix / 2d array of the shape\n",
        "        [Number of Nodes, Node Feature size]\n",
        "        \"\"\"\n",
        "        all_node_feats = []\n",
        "\n",
        "        for atom in mol.GetAtoms():\n",
        "            node_feats = []\n",
        "            # Feature 1: Atomic number        \n",
        "            node_feats.append(atom.GetAtomicNum())\n",
        "            # Feature 2: Atom degree\n",
        "            node_feats.append(atom.GetDegree())\n",
        "            # Feature 3: Formal charge\n",
        "            node_feats.append(atom.GetFormalCharge())\n",
        "            # Feature 4: Hybridization\n",
        "            node_feats.append(atom.GetHybridization())\n",
        "            # Feature 5: Aromaticity\n",
        "            node_feats.append(atom.GetIsAromatic())\n",
        "            # Feature 6: Total Num Hs\n",
        "            node_feats.append(atom.GetTotalNumHs())\n",
        "            # Feature 7: Radical Electrons\n",
        "            node_feats.append(atom.GetNumRadicalElectrons())\n",
        "            # Feature 8: In Ring\n",
        "            node_feats.append(atom.IsInRing())\n",
        "            # Feature 9: Chirality\n",
        "            node_feats.append(atom.GetChiralTag())\n",
        "\n",
        "            # Append node features to matrix\n",
        "            all_node_feats.append(node_feats)\n",
        "\n",
        "        all_node_feats = np.asarray(all_node_feats)\n",
        "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
        "\n",
        "    def _get_edge_features(self, mol):\n",
        "        \"\"\" \n",
        "        This will return a matrix / 2d array of the shape\n",
        "        [Number of edges, Edge Feature size]\n",
        "        \"\"\"\n",
        "        all_edge_feats = []\n",
        "\n",
        "        for bond in mol.GetBonds():\n",
        "            edge_feats = []\n",
        "            # Feature 1: Bond type (as double)\n",
        "            edge_feats.append(bond.GetBondTypeAsDouble())\n",
        "            # Feature 2: Rings\n",
        "            edge_feats.append(bond.IsInRing())\n",
        "            # Append node features to matrix (twice, per direction)\n",
        "            all_edge_feats += [edge_feats, edge_feats]\n",
        "\n",
        "        all_edge_feats = np.asarray(all_edge_feats)\n",
        "        return torch.tensor(all_edge_feats, dtype=torch.float)\n",
        "\n",
        "    def _get_adjacency_info(self, mol):\n",
        "        \"\"\"\n",
        "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
        "        but we want to be sure that the order of the indices\n",
        "        matches the order of the edge features\n",
        "        \"\"\"\n",
        "        edge_indices = []\n",
        "        for bond in mol.GetBonds():\n",
        "            i = bond.GetBeginAtomIdx()\n",
        "            j = bond.GetEndAtomIdx()\n",
        "            edge_indices += [[i, j], [j, i]]\n",
        "\n",
        "        edge_indices = torch.tensor(edge_indices)\n",
        "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
        "        return edge_indices\n",
        "\n",
        "    def _get_labels(self, label):\n",
        "        label = np.asarray([label])\n",
        "        return torch.tensor(label, dtype=torch.int64)\n",
        "\n",
        "    def len(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def get(self, idx):\n",
        "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
        "            - Is not needed for PyG's InMemoryDataset\n",
        "        \"\"\"\n",
        "        if self.test:\n",
        "            data = torch.load(os.path.join(self.processed_dir, \n",
        "                                 f'data_test_{idx}.pt'))\n",
        "        else:\n",
        "            data = torch.load(os.path.join(self.processed_dir, \n",
        "                                 f'data_{idx}.pt'))   \n",
        "        return data"
      ],
      "metadata": {
        "id": "oVOJCk8gRKtX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = HIVDataset(root='data/',filename='HIV_train_oversampled.csv')\n",
        "test_dataset = HIVDataset(root='data/',filename='HIV_test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dnwE9t0RLEC",
        "outputId": "7879ee84-ee4d-424e-8070-93d17a54375a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data/raw/HIV_train_oversampled.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 71634/71634 [04:18<00:00, 276.74it/s]\n",
            "Done!\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data/raw/HIV_test.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3999/3999 [00:13<00:00, 288.66it/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, feature_size, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        num_classes = 2\n",
        "        self.conv1 = GCNConv(feature_size, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Obtain node embeddings \n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = gap(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "mKAn_uTxSPax"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(torch.nn.Module):\n",
        "  def __init__(self,feature_size):\n",
        "    super(GNN, self).__init__()\n",
        "    num_classes=1\n",
        "    embedding_size=1024\n",
        "    self.conv1 = GATConv(feature_size,embedding_size, heads=3, dropout =0.3)\n",
        "    self.head_transform1 = Linear(embedding_size*3, embedding_size)\n",
        "    self.pool1 = TopKPooling(embedding_size,ratio=0.8)\n",
        "\n",
        "    self.conv2 = GATConv(embedding_size, embedding_size, heads=3, dropout =0.3)\n",
        "    self.head_transform2 = Linear(embedding_size*3, embedding_size)\n",
        "    self.pool2 = TopKPooling(embedding_size,ratio=0.5)\n",
        "\n",
        "    self.conv3 = GATConv(embedding_size, embedding_size, heads=3, dropout =0.3)\n",
        "    self.head_transform3 = Linear(embedding_size*3, embedding_size)\n",
        "    self.pool3 = TopKPooling(embedding_size,ratio=0.2)\n",
        "\n",
        "    self.linear1 = Linear(embedding_size*2,1024)\n",
        "    self.linear2 = Linear(1024,num_classes)\n",
        "\n",
        "  def forward(self, x, edge_attr,edge_index,batch_index):\n",
        "    x = self.conv1(x,edge_index)\n",
        "    x = self.head_transform1(x)\n",
        "\n",
        "    x,edge_index,edge_attr,batch_index, _ , _ = self.pool1(x,edge_index,None, batch_index)\n",
        "\n",
        "    x1 = torch.cat([gmp(x,batch_index),gap(x,batch_index)],dim=1)\n",
        "\n",
        "    x = self.conv2(x,edge_index)\n",
        "    x = self.head_transform2(x)\n",
        "\n",
        "    x,edge_index,edge_attr,batch_index, _ , _ = self.pool2(x,edge_index,None, batch_index)\n",
        "\n",
        "    x2 = torch.cat([gmp(x,batch_index),gap(x,batch_index)],dim=1)\n",
        "\n",
        "    x = self.conv3(x,edge_index)\n",
        "    x = self.head_transform3(x)\n",
        "\n",
        "    x,edge_index,edge_attr,batch_index, _ , _ = self.pool3(x,edge_index,None, batch_index)\n",
        "\n",
        "    x3 = torch.cat([gmp(x,batch_index),gap(x,batch_index)],dim=1)\n",
        "\n",
        "    x=x1+x2+x3\n",
        "\n",
        "    x = self.linear1(x).relu()\n",
        "    x = F.dropout(x,p=0.5, training=self.training) \n",
        "    x = self.linear2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "hdA2rMC-Stx_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model = GCN(train_dataset[0].x.shape[1], 256)"
      ],
      "metadata": {
        "id": "1Epgrq01Svsc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gat_model = GNN(train_dataset[0].x.shape[1])"
      ],
      "metadata": {
        "id": "-OLO8zMNSy8G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gat_model.load_state_dict(torch.load('/content/drive/MyDrive/GNN_HIV/models/model-hiv-60epochs.pt',map_location=torch.device('cpu')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OQUKJPZTH8w",
        "outputId": "c1496a15-16b9-4028-800d-a6fc1b20baaa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model.load_state_dict(torch.load('/content/drive/MyDrive/GNN_HIV/models/gcn/model-hiv-500epochs.pt',map_location = torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAuZN_HJTfWi",
        "outputId": "e9c41a8c-46d2-4ab5-f002-d7ceae36d42f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "RrnIjlLpQ5D4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gat_model.to(device)\n",
        "gcn_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwmi4KPBTtoM",
        "outputId": "f3e30a14-6d52-4c4a-9377-d41ec732d4c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (conv1): GCNConv(9, 256)\n",
              "  (conv2): GCNConv(256, 256)\n",
              "  (conv3): GCNConv(256, 256)\n",
              "  (lin): Linear(256, 2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=True)"
      ],
      "metadata": {
        "id": "OCYl7rN2T3gp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.tensor([1,10],dtype=torch.float32).to(device)\n",
        "gcn_loss_fn = torch.nn.CrossEntropyLoss(weight= weights)\n",
        "gat_loss_fn = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "d7gqVb9_UFmp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Individual Test Losses"
      ],
      "metadata": {
        "id": "2gXxqapRUdNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model.eval()\n",
        "with torch.no_grad():\n",
        "  test_preds = []\n",
        "  test_labels = []\n",
        "  running_loss = 0.0\n",
        "  steps =0 \n",
        "  for _, batch in enumerate(tqdm(test_loader)):\n",
        "    batch.to(device)\n",
        "    pred = gcn_model(batch.x.float(),batch.edge_index, batch.batch)\n",
        "    # print(batch.y)\n",
        "    loss = gcn_loss_fn(pred, batch.y)\n",
        "    test_preds.append(np.argmax(pred.cpu().detach().numpy(),axis=1))\n",
        "    test_labels.append(batch.y.cpu().detach().numpy())\n",
        "    running_loss += loss.item()\n",
        "    steps+=1\n",
        "  test_preds = np.concatenate(test_preds).ravel()\n",
        "  test_labels = np.concatenate(test_labels).ravel()\n",
        "  acc= accuracy_score(test_labels, test_preds)\n",
        "  print(f'\\nTest Loss : {running_loss/steps} \\n Test Accuracy : {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoyS1-KOTw4x",
        "outputId": "5d278be5-2893-4f17-ea54-b8b0bcf4d828"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:05<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Loss : 0.7878403961658478 \n",
            " Test Accuracy : 0.6639159789947486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(test_labels,test_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeKULzEOWali",
        "outputId": "028e1582-ddfb-4d8d-ef75-e7b0d5f5efc7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2516, 1318],\n",
              "       [  26,  139]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels,test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spwr1JGdX6RI",
        "outputId": "7dac327a-ee8a-466b-cf40-fba16c0339da"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.66      0.79      3834\n",
            "           1       0.10      0.84      0.17       165\n",
            "\n",
            "    accuracy                           0.66      3999\n",
            "   macro avg       0.54      0.75      0.48      3999\n",
            "weighted avg       0.95      0.66      0.76      3999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gat_model.eval()\n",
        "with torch.no_grad():\n",
        "  test_preds = []\n",
        "  test_labels = []\n",
        "  running_loss = 0.0\n",
        "  steps =0 \n",
        "  for _, batch in enumerate(tqdm(test_loader)):\n",
        "    batch.to(device)\n",
        "    pred = gat_model(batch.x.float(), batch.edge_attr.float(),batch.edge_index, batch.batch)\n",
        "    # print(batch.y)\n",
        "    loss = gat_loss_fn(torch.squeeze(pred), batch.y.float())\n",
        "    test_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
        "    test_labels.append(batch.y.cpu().detach().numpy())\n",
        "    running_loss += loss.item()\n",
        "    steps+=1\n",
        "  test_preds = np.concatenate(test_preds).ravel()\n",
        "  test_labels = np.concatenate(test_labels).ravel()\n",
        "  acc= accuracy_score(test_labels, test_preds)\n",
        "  print(f'\\nTest Loss : {running_loss/steps} \\n Test Accuracy : {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jf5Nv79UW7K",
        "outputId": "b0798c1a-765b-4a9c-e572-f72b70e7732f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [01:42<00:00,  6.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Loss : 0.2757689142599702 \n",
            " Test Accuracy : 0.9154788697174293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(test_labels,test_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i95b3eIaWYUN",
        "outputId": "b3a92447-7a77-4cb9-ba8a-b74226832d3a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3642,  192],\n",
              "       [ 146,   19]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels,test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EQ9bYnrX-V_",
        "outputId": "38c89d6a-fb40-4def-e612-19c1bf3fa692"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.96      3834\n",
            "           1       0.09      0.12      0.10       165\n",
            "\n",
            "    accuracy                           0.92      3999\n",
            "   macro avg       0.53      0.53      0.53      3999\n",
            "weighted avg       0.93      0.92      0.92      3999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def sigmoid(x):\n",
        "  return 1/ (1+math.exp(-x))"
      ],
      "metadata": {
        "id": "SBYb52eZfeqF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  test_preds = []\n",
        "  test_labels = []\n",
        "  for _, batch in enumerate(tqdm(test_loader)):\n",
        "    batch.to(device)\n",
        "    # get predictions from gcn\n",
        "    gcn_preds = gcn_model(batch.x.float(),batch.edge_index, batch.batch)\n",
        "    gcn_transformed = []\n",
        "    for pred in gcn_preds:\n",
        "      if(pred[1] > pred[0]):\n",
        "        gcn_transformed.append(sigmoid(pred[1]))\n",
        "      else:\n",
        "        gcn_transformed.append(1-sigmoid(pred[0]))\n",
        "    gcn_transformed = np.array(gcn_transformed)\n",
        "    gcn_transformed = gcn_transformed.reshape(gcn_transformed.shape[0],1) # expand dims to match gat_pred\n",
        "\n",
        "    # get predictions from gat \n",
        "    gat_pred = gat_model(batch.x.float(), batch.edge_attr.float(),batch.edge_index, batch.batch)\n",
        "    gat_pred = torch.sigmoid(gat_pred.cpu().detach()).numpy()\n",
        "    \n",
        "    # ensemble \n",
        "    test_preds.append(np.rint((gat_pred + gcn_transformed) /2 ) )\n",
        "    test_labels.append(batch.y.cpu().detach().numpy())\n",
        "  test_preds = np.concatenate(test_preds).ravel()\n",
        "  test_labels = np.concatenate(test_labels).ravel()\n",
        "  acc= accuracy_score(test_labels, test_preds)\n",
        "  print(f'\\n Ensemble Test Accuracy : {acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz-MwHnVYSFL",
        "outputId": "c8e2bc63-3534-434d-8b15-bcbdf66ae057"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [01:37<00:00,  6.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Ensemble Test Accuracy : 0.8639659914978745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(test_labels,test_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1Ea8ZkLc3l7",
        "outputId": "cd411e4f-92b8-4b56-f386-73f0b25f428e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3337,  497],\n",
              "       [  47,  118]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels,test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJLI80Xpi0dm",
        "outputId": "018b9bc2-e3c4-4d85-a002-bd1ad2140d3a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.87      0.92      3834\n",
            "           1       0.19      0.72      0.30       165\n",
            "\n",
            "    accuracy                           0.86      3999\n",
            "   macro avg       0.59      0.79      0.61      3999\n",
            "weighted avg       0.95      0.86      0.90      3999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L3wz5j2QjAAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}