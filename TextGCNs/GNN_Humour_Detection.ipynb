{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN_Humour_Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcNcbMTPEe6djntnFrBoml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaspradhan/Graph-Neural-Networks/blob/main/TextGCNs/GNN_Humour_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries and Installation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8g21qZ9k9g6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZFapr9Cqgd2_",
        "outputId": "66529d49-623f-4d01-9170-0aea59c26699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=0e37e29445353c687b2db2c426442c8f4b2c05f1c461a404d7f497bb0ce66e78\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built tf-geometric ogb-lite tf-sparse littleutils\n",
            "Installing collected packages: littleutils, outdated, tf-sparse, ogb-lite, tf-geometric\n",
            "Successfully installed littleutils-0.2.2 ogb-lite-0.0.3 outdated-0.2.1 tf-geometric-0.0.81 tf-sparse-0.0.10\n"
          ]
        }
      ],
      "source": [
        "! pip install -U tf_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tf_geometric.utils import tf_utils\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "# # In case of any corpus are missing \n",
        "# download all-nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tf_geometric as tfg\n",
        "import pickle\n",
        "import re\n"
      ],
      "metadata": {
        "id": "yz716-y_hhc1",
        "outputId": "47520917-3a2c-473b-94a9-ebd50bedb227",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/dataset.csv')"
      ],
      "metadata": {
        "id": "xRE_gizfhqWm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "dM3beu3zhxtw",
        "outputId": "b05c480f-6aaf-45f0-866d-35bec442f332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  humor\n",
              "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
              "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
              "2  What do you call a turtle without its shell? d...   True\n",
              "3      5 reasons the 2016 election feels so personal  False\n",
              "4  Pasco police shot mexican migrant from behind,...  False"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95d57888-2f8f-4f85-acfd-7069ff9aa477\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you call a turtle without its shell? d...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5 reasons the 2016 election feels so personal</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95d57888-2f8f-4f85-acfd-7069ff9aa477')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95d57888-2f8f-4f85-acfd-7069ff9aa477 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95d57888-2f8f-4f85-acfd-7069ff9aa477');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "Hsipgykth2Sa",
        "outputId": "4fd6f844-ce5f-427e-f160-dd5d19ec3609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby('humor')['text'].count()\n",
        "# dataset is balanced"
      ],
      "metadata": {
        "id": "NNg5XgIFh-wJ",
        "outputId": "dfb0c37f-9233-4974-dad7-133bfc75b52e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "humor\n",
              "False    100000\n",
              "True     100000\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "EZ2FUparj5JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(x):\n",
        "  x = x.lower()\n",
        "  x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
        "  x = x.encode('ascii', 'ignore').decode()\n",
        "  x = re.sub(r'https*\\S+', ' ', x)\n",
        "  x = re.sub(r'@\\S+', ' ', x)\n",
        "  x = re.sub(r'#\\S+', ' ', x)\n",
        "  x = re.sub(r'\\'\\w+', '', x)\n",
        "  x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
        "  x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
        "  x = re.sub(r'\\s{2,}', ' ', x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "D5x4wWYBi_c2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "OOyV7BXMiDqo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['labels'] = data['humor'].apply(lambda x: 1 if x==True else 0)"
      ],
      "metadata": {
        "id": "jSQChaDukFNi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data['text']\n",
        "labels = data['labels']"
      ],
      "metadata": {
        "id": "--Qe5MC2kpX8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)"
      ],
      "metadata": {
        "id": "0bVZxUkIkuNQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating the PMI Model for calculating pointwise mutual info for preprocessing as a graph\n"
      ],
      "metadata": {
        "id": "5d2m_fyflMuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PMIModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word_counter = None\n",
        "        self.pair_counter = None\n",
        "\n",
        "    def get_pair_id(self, word0, word1):\n",
        "        pair_id = tuple(sorted([word0, word1]))\n",
        "        return pair_id\n",
        "\n",
        "    def fit(self, sequences, window_size):\n",
        "\n",
        "        self.word_counter = Counter()\n",
        "        self.pair_counter = Counter()\n",
        "        num_windows = 0\n",
        "        for sequence in tqdm(sequences):\n",
        "            for offset in range(len(sequence) - window_size):\n",
        "                window = sequence[offset:offset + window_size]\n",
        "                num_windows += 1\n",
        "                for i, word0 in enumerate(window):\n",
        "                    self.word_counter[word0] += 1\n",
        "                    for j, word1 in enumerate(window[i + 1:]):\n",
        "                        pair_id = self.get_pair_id(word0, word1)\n",
        "                        self.pair_counter[pair_id] += 1\n",
        "\n",
        "        for word, count in self.word_counter.items():\n",
        "            self.word_counter[word] = count / num_windows\n",
        "        for pair_id, count in self.pair_counter.items():\n",
        "            self.pair_counter[pair_id] = count / num_windows\n",
        "\n",
        "    def transform(self, word0, word1):\n",
        "        prob_a = self.word_counter[word0]\n",
        "        prob_b = self.word_counter[word1]\n",
        "        pair_id = self.get_pair_id(word0, word1)\n",
        "        prob_pair = self.pair_counter[pair_id]\n",
        "\n",
        "        if prob_a == 0 or prob_b == 0 or prob_pair == 0:\n",
        "            return 0\n",
        "\n",
        "        pmi = np.log(prob_pair / (prob_a * prob_b))\n",
        "        # print(word0, word1, pmi)\n",
        "        pmi = np.maximum(pmi, 0.0)\n",
        "        # print(pmi)\n",
        "        return pmi"
      ],
      "metadata": {
        "id": "e7NrWG7VlhxX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_word_graph(num_words, pmi_model, embedding_size):\n",
        "    x = tf.Variable(tf.random.truncated_normal([num_words, embedding_size], stddev=1 / np.sqrt(embedding_size)),\n",
        "                    dtype=tf.float32)\n",
        "    edges = []\n",
        "    edge_weight = []\n",
        "    for (word0, word1) in pmi_model.pair_counter.keys():\n",
        "        pmi = pmi_model.transform(word0, word1)\n",
        "        if pmi > 0:\n",
        "            edges.append([word0, word1])\n",
        "            edge_weight.append(pmi)\n",
        "            edges.append([word1, word0])\n",
        "            edge_weight.append(pmi)\n",
        "    edge_index = np.array(edges).T\n",
        "    return tfg.Graph(x=x, edge_index=edge_index, edge_weight=edge_weight)"
      ],
      "metadata": {
        "id": "Op1fgMLmlkDo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_combined_graph(word_graph, sequences, embedding_size):\n",
        "    num_words = word_graph.num_nodes\n",
        "    x = tf.zeros([len(sequences), embedding_size], dtype=tf.float32)\n",
        "    edges = []\n",
        "    edge_weight = []\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        doc_node_index = num_words + i\n",
        "        for word in sequence:\n",
        "            edges.append([doc_node_index, word])  # only directed edge\n",
        "            edge_weight.append(1.0)  # use BOW instaead of TF-IDF\n",
        "\n",
        "    edge_index = np.array(edges).T\n",
        "    x = tf.concat([word_graph.x, x], axis=0)\n",
        "    edge_index = np.concatenate([word_graph.edge_index, edge_index], axis=1)\n",
        "    edge_weight = np.concatenate([word_graph.edge_weight, edge_weight], axis=0)\n",
        "    return tfg.Graph(x=x, edge_index=edge_index, edge_weight=edge_weight)"
      ],
      "metadata": {
        "id": "FsYHFbaZll5m"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pmi_cache_path = \"cached_pmi_model.p\"\n",
        "if os.path.exists(pmi_cache_path):\n",
        "    with open(pmi_cache_path, \"rb\") as f:\n",
        "        pmi_model = pickle.load(f)\n",
        "else:\n",
        "    pmi_model = PMIModel()\n",
        "    pmi_model.fit(train_sequences, window_size=6)\n",
        "    with open(pmi_cache_path, \"wb\") as f:\n",
        "        pickle.dump(pmi_model, f)\n",
        "\n",
        "embedding_size = 150\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "word_graph = build_word_graph(num_words, pmi_model, embedding_size)\n",
        "train_combined_graph = build_combined_graph(word_graph, train_sequences, embedding_size)\n",
        "test_combined_graph = build_combined_graph(word_graph, test_sequences, embedding_size)\n",
        "\n",
        "print(word_graph)\n",
        "print(train_combined_graph)\n",
        "print(test_combined_graph)\n",
        "\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "YNBxUN1AloDg",
        "outputId": "480e3ca0-94c5-4045-c91b-dc03b2d87492",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160000/160000 [00:12<00:00, 13055.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Shape: x => (53594, 150)\tedge_index => (2, 2633384)\ty => None\n",
            "Graph Shape: x => (213594, 150)\tedge_index => (2, 3796835)\ty => None\n",
            "Graph Shape: x => (93594, 150)\tedge_index => (2, 2918358)\ty => None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.gcn0 = tfg.layers.GCN(100, activation=tf.nn.relu)\n",
        "        self.gcn1 = tfg.layers.GCN(num_classes)\n",
        "        self.dropout = keras.layers.Dropout(0.5)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None, cache=None):\n",
        "        x, edge_index, edge_weight = inputs\n",
        "        h = self.gcn0([x, edge_index, edge_weight], cache=cache)\n",
        "        h = self.dropout(h, training=training)\n",
        "        h = self.gcn1([h, edge_index, edge_weight], cache=cache)\n",
        "        return h"
      ],
      "metadata": {
        "id": "qv8XJkMHlqnv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCNModel()\n",
        "model.gcn0.cache_normed_edge(train_combined_graph)\n",
        "model.gcn0.cache_normed_edge(test_combined_graph)"
      ],
      "metadata": {
        "id": "lyn13p-GlsgZ",
        "outputId": "e91397ea-1556-4f3a-ef5d-b994a257908c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tf_geometric/layers/conv/gcn.py:79: DeprecationWarning: 'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\n",
            "  warnings.warn(\"'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\", DeprecationWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/tf_geometric/layers/conv/gcn.py:79: DeprecationWarning: 'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\n",
            "  warnings.warn(\"'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\", DeprecationWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf_utils.function\n",
        "def forward(graph, training=False):\n",
        "    logits = model([graph.x, graph.edge_index, graph.edge_weight], cache=graph.cache, training=training)\n",
        "    logits = logits[num_words:]\n",
        "    return logits"
      ],
      "metadata": {
        "id": "iRxx8p3TlupJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(logits, labels):\n",
        "    losses = tf.nn.softmax_cross_entropy_with_logits(\n",
        "        logits=logits,\n",
        "        labels=tf.one_hot(labels, depth=num_classes)\n",
        "    )\n",
        "    mean_loss = tf.reduce_mean(losses)\n",
        "    return mean_loss"
      ],
      "metadata": {
        "id": "VghBVrUZlwvC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-2)\n"
      ],
      "metadata": {
        "id": "hMslUWwelyYU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(1000):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = forward(train_combined_graph, training=True)\n",
        "        mean_loss = compute_loss(logits, train_labels)\n",
        "\n",
        "    vars = tape.watched_variables()\n",
        "    grads = tape.gradient(mean_loss, vars)\n",
        "    optimizer.apply_gradients(zip(grads, vars))\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        logits = forward(test_combined_graph)\n",
        "        preds = tf.argmax(logits, axis=-1)\n",
        "        corrects = tf.cast(tf.equal(preds, test_labels), tf.float32)\n",
        "        accuracy = tf.reduce_mean(corrects)\n",
        "        print(\"step = {}\\tloss = {}\\ttest_accuracy = {}\".format(step, mean_loss, accuracy))"
      ],
      "metadata": {
        "id": "A-ORjZYvlz2G",
        "outputId": "2a9c5fc0-591e-4610-b2cd-fccf38b721a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 0\tloss = 0.6935877203941345\ttest_accuracy = 0.4953500032424927\n",
            "step = 10\tloss = 0.6853223443031311\ttest_accuracy = 0.5099999904632568\n",
            "step = 20\tloss = 0.6832590699195862\ttest_accuracy = 0.5077000260353088\n",
            "step = 30\tloss = 0.6815218925476074\ttest_accuracy = 0.5077499747276306\n",
            "step = 40\tloss = 0.6798995137214661\ttest_accuracy = 0.5080500245094299\n",
            "step = 50\tloss = 0.67740797996521\ttest_accuracy = 0.5081750154495239\n",
            "step = 60\tloss = 0.6751867532730103\ttest_accuracy = 0.5094749927520752\n",
            "step = 70\tloss = 0.6721969842910767\ttest_accuracy = 0.510824978351593\n",
            "step = 80\tloss = 0.6689457893371582\ttest_accuracy = 0.5122249722480774\n",
            "step = 90\tloss = 0.6657230257987976\ttest_accuracy = 0.5137749910354614\n",
            "step = 100\tloss = 0.663317084312439\ttest_accuracy = 0.5181000232696533\n",
            "step = 110\tloss = 0.6612421870231628\ttest_accuracy = 0.5275499820709229\n",
            "step = 120\tloss = 0.6599794626235962\ttest_accuracy = 0.5206999778747559\n",
            "step = 130\tloss = 0.6580613255500793\ttest_accuracy = 0.5227500200271606\n",
            "step = 140\tloss = 0.6569938063621521\ttest_accuracy = 0.5406500101089478\n",
            "step = 150\tloss = 0.6553710103034973\ttest_accuracy = 0.5346750020980835\n",
            "step = 160\tloss = 0.6543174386024475\ttest_accuracy = 0.5619999766349792\n",
            "step = 170\tloss = 0.6536961197853088\ttest_accuracy = 0.6099249720573425\n",
            "step = 180\tloss = 0.6516911387443542\ttest_accuracy = 0.5422750115394592\n",
            "step = 190\tloss = 0.6519584059715271\ttest_accuracy = 0.5706499814987183\n",
            "step = 200\tloss = 0.6509293913841248\ttest_accuracy = 0.5616750121116638\n",
            "step = 210\tloss = 0.650847852230072\ttest_accuracy = 0.5947250127792358\n",
            "step = 220\tloss = 0.6493288278579712\ttest_accuracy = 0.5657749772071838\n",
            "step = 230\tloss = 0.6498115062713623\ttest_accuracy = 0.5907750129699707\n",
            "step = 240\tloss = 0.6485234498977661\ttest_accuracy = 0.6059250235557556\n",
            "step = 250\tloss = 0.6479496359825134\ttest_accuracy = 0.5958750247955322\n",
            "step = 260\tloss = 0.6484652757644653\ttest_accuracy = 0.6103249788284302\n",
            "step = 270\tloss = 0.6485081315040588\ttest_accuracy = 0.590749979019165\n",
            "step = 280\tloss = 0.6480894088745117\ttest_accuracy = 0.59232497215271\n",
            "step = 290\tloss = 0.6481928825378418\ttest_accuracy = 0.6137750148773193\n",
            "step = 300\tloss = 0.647940993309021\ttest_accuracy = 0.5882250070571899\n",
            "step = 310\tloss = 0.6463436484336853\ttest_accuracy = 0.6035249829292297\n",
            "step = 320\tloss = 0.6471402645111084\ttest_accuracy = 0.6046749949455261\n",
            "step = 330\tloss = 0.6466185450553894\ttest_accuracy = 0.6201750040054321\n",
            "step = 340\tloss = 0.646003007888794\ttest_accuracy = 0.6091750264167786\n",
            "step = 350\tloss = 0.6461323499679565\ttest_accuracy = 0.61285001039505\n",
            "step = 360\tloss = 0.645179808139801\ttest_accuracy = 0.6205250024795532\n",
            "step = 370\tloss = 0.6446139812469482\ttest_accuracy = 0.6010749936103821\n",
            "step = 380\tloss = 0.6453772187232971\ttest_accuracy = 0.6312000155448914\n",
            "step = 390\tloss = 0.6462392807006836\ttest_accuracy = 0.6154000163078308\n",
            "step = 400\tloss = 0.6436750888824463\ttest_accuracy = 0.6194249987602234\n",
            "step = 410\tloss = 0.6447141170501709\ttest_accuracy = 0.6409249901771545\n",
            "step = 420\tloss = 0.6448174715042114\ttest_accuracy = 0.6299999952316284\n",
            "step = 430\tloss = 0.646030843257904\ttest_accuracy = 0.6094750165939331\n",
            "step = 440\tloss = 0.6433576941490173\ttest_accuracy = 0.6323750019073486\n",
            "step = 450\tloss = 0.6445297002792358\ttest_accuracy = 0.604075014591217\n",
            "step = 460\tloss = 0.6430443525314331\ttest_accuracy = 0.6068500280380249\n",
            "step = 470\tloss = 0.6432294845581055\ttest_accuracy = 0.6412500143051147\n",
            "step = 480\tloss = 0.6434255242347717\ttest_accuracy = 0.625374972820282\n",
            "step = 490\tloss = 0.6436307430267334\ttest_accuracy = 0.6292750239372253\n",
            "step = 500\tloss = 0.642524242401123\ttest_accuracy = 0.6445000171661377\n",
            "step = 510\tloss = 0.6418761014938354\ttest_accuracy = 0.6274999976158142\n",
            "step = 520\tloss = 0.6419293284416199\ttest_accuracy = 0.6401749849319458\n",
            "step = 530\tloss = 0.6410603523254395\ttest_accuracy = 0.6369249820709229\n",
            "step = 540\tloss = 0.6423753499984741\ttest_accuracy = 0.6341500282287598\n",
            "step = 550\tloss = 0.641010046005249\ttest_accuracy = 0.6398749947547913\n",
            "step = 560\tloss = 0.6427032947540283\ttest_accuracy = 0.6305999755859375\n",
            "step = 570\tloss = 0.6435694098472595\ttest_accuracy = 0.6264500021934509\n",
            "step = 580\tloss = 0.6408675909042358\ttest_accuracy = 0.6549749970436096\n",
            "step = 590\tloss = 0.6411529779434204\ttest_accuracy = 0.6367999911308289\n",
            "step = 600\tloss = 0.6419426202774048\ttest_accuracy = 0.6287500262260437\n",
            "step = 610\tloss = 0.6420713663101196\ttest_accuracy = 0.6404250264167786\n",
            "step = 620\tloss = 0.6430586576461792\ttest_accuracy = 0.6571499705314636\n",
            "step = 630\tloss = 0.6412241458892822\ttest_accuracy = 0.6122999787330627\n",
            "step = 640\tloss = 0.6405512690544128\ttest_accuracy = 0.6514250040054321\n",
            "step = 650\tloss = 0.6425376534461975\ttest_accuracy = 0.6438249945640564\n",
            "step = 660\tloss = 0.6411541700363159\ttest_accuracy = 0.6394749879837036\n",
            "step = 670\tloss = 0.6396080255508423\ttest_accuracy = 0.6559749841690063\n",
            "step = 680\tloss = 0.6397294998168945\ttest_accuracy = 0.6299750208854675\n",
            "step = 690\tloss = 0.6392437219619751\ttest_accuracy = 0.654574990272522\n",
            "step = 700\tloss = 0.6423419117927551\ttest_accuracy = 0.6410499811172485\n",
            "step = 710\tloss = 0.6425576210021973\ttest_accuracy = 0.6430000066757202\n",
            "step = 720\tloss = 0.6431755423545837\ttest_accuracy = 0.6529750227928162\n",
            "step = 730\tloss = 0.6411299109458923\ttest_accuracy = 0.6442750096321106\n",
            "step = 740\tloss = 0.6400805711746216\ttest_accuracy = 0.647599995136261\n",
            "step = 750\tloss = 0.6423276662826538\ttest_accuracy = 0.6545000076293945\n",
            "step = 760\tloss = 0.6415009498596191\ttest_accuracy = 0.6237999796867371\n",
            "step = 770\tloss = 0.6387268304824829\ttest_accuracy = 0.6496750116348267\n",
            "step = 780\tloss = 0.6392008066177368\ttest_accuracy = 0.6403499841690063\n",
            "step = 790\tloss = 0.6372564435005188\ttest_accuracy = 0.6465499997138977\n",
            "step = 800\tloss = 0.6404135823249817\ttest_accuracy = 0.6461499929428101\n",
            "step = 810\tloss = 0.641677737236023\ttest_accuracy = 0.6619750261306763\n",
            "step = 820\tloss = 0.6379521489143372\ttest_accuracy = 0.6343250274658203\n",
            "step = 830\tloss = 0.6402521729469299\ttest_accuracy = 0.6598749756813049\n",
            "step = 840\tloss = 0.636480450630188\ttest_accuracy = 0.6513500213623047\n",
            "step = 850\tloss = 0.6403241157531738\ttest_accuracy = 0.6457750201225281\n",
            "step = 860\tloss = 0.6413259506225586\ttest_accuracy = 0.6600750088691711\n",
            "step = 870\tloss = 0.6367437243461609\ttest_accuracy = 0.6354749798774719\n",
            "step = 880\tloss = 0.6365556716918945\ttest_accuracy = 0.633400022983551\n",
            "step = 890\tloss = 0.6399230360984802\ttest_accuracy = 0.6597499847412109\n",
            "step = 900\tloss = 0.637647271156311\ttest_accuracy = 0.6263499855995178\n",
            "step = 910\tloss = 0.6396007537841797\ttest_accuracy = 0.6442499756813049\n",
            "step = 920\tloss = 0.637152910232544\ttest_accuracy = 0.6380500197410583\n",
            "step = 930\tloss = 0.6340826749801636\ttest_accuracy = 0.6337500214576721\n",
            "step = 940\tloss = 0.6343778967857361\ttest_accuracy = 0.6555749773979187\n",
            "step = 950\tloss = 0.6342077851295471\ttest_accuracy = 0.6575250029563904\n",
            "step = 960\tloss = 0.6340927481651306\ttest_accuracy = 0.6404250264167786\n",
            "step = 970\tloss = 0.6352458596229553\ttest_accuracy = 0.6305000185966492\n",
            "step = 980\tloss = 0.6352812051773071\ttest_accuracy = 0.663474977016449\n",
            "step = 990\tloss = 0.6403211951255798\ttest_accuracy = 0.6641499996185303\n"
          ]
        }
      ]
    }
  ]
}