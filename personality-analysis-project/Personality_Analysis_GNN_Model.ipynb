{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personality_Analysis_GNN_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsfDxQQKF3LyQYapV6u0I4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaspradhan/Graph-Neural-Networks/blob/main/personality-analysis-project/Personality_Analysis_GNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U tf_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZIvNJlc0Q4q",
        "outputId": "83528212-2c6c-4a45-e39b-e1a30fd43c41"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf_geometric in /usr/local/lib/python3.7/dist-packages (0.0.85)\n",
            "Requirement already satisfied: tf-sparse>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from tf_geometric) (0.0.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tf_geometric) (4.64.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from tf_geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from tf_geometric) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf_geometric) (1.4.1)\n",
            "Requirement already satisfied: ogb-lite>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from tf_geometric) (0.0.3)\n",
            "Requirement already satisfied: numpy>=1.17.4 in /usr/local/lib/python3.7/dist-packages (from tf_geometric) (1.21.6)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb-lite>=0.0.3->tf_geometric) (0.2.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb-lite>=0.0.3->tf_geometric) (1.3.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb-lite>=0.0.3->tf_geometric) (1.15.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb-lite>=0.0.3->tf_geometric) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb-lite>=0.0.3->tf_geometric) (2.23.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb-lite>=0.0.3->tf_geometric) (0.2.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb-lite>=0.0.3->tf_geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb-lite>=0.0.3->tf_geometric) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->tf_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->tf_geometric) (1.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb-lite>=0.0.3->tf_geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb-lite>=0.0.3->tf_geometric) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb-lite>=0.0.3->tf_geometric) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tf_geometric.utils import tf_utils\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "# # In case of any corpus are missing \n",
        "# download all-nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tf_geometric as tfg\n",
        "import pickle\n",
        "import re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ0V2i680KFW",
        "outputId": "1e4f099c-7943-4341-9132-8f7e60f03400"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/fft/__init__.py:97: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\n",
            "  from numpy.dual import register_func\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py:17: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
            "  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio5.py:98: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from .mio5_utils import VarReader5\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ydm5E6rx5LDN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/mbti_cleaned.csv')\n"
      ],
      "metadata": {
        "id": "la-EiPTw0WNL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5TH1HXCW0f5l",
        "outputId": "7c59ffa0-e452-496b-c6a5-1e0e2379ea05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  type  Number of posts  \\\n",
              "0           0  INFJ               50   \n",
              "1           1  ENTP               50   \n",
              "2           2  INTP               50   \n",
              "3           3  INTJ               50   \n",
              "4           4  ENTJ               50   \n",
              "\n",
              "                                               Posts  \n",
              "0    intj moments    sportscenter    plays    pra...  \n",
              "1   finding  lack    these posts very alarmingsex...  \n",
              "2  good       course  which    know thats  blessi...  \n",
              "3  dear intp    enjoyed  conversation  other   es...  \n",
              "4  youre firedthats another silly misconception t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-924dce18-c411-483c-9ba6-2f82ac9f8c61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>type</th>\n",
              "      <th>Number of posts</th>\n",
              "      <th>Posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>50</td>\n",
              "      <td>intj moments    sportscenter    plays    pra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ENTP</td>\n",
              "      <td>50</td>\n",
              "      <td>finding  lack    these posts very alarmingsex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>INTP</td>\n",
              "      <td>50</td>\n",
              "      <td>good       course  which    know thats  blessi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>50</td>\n",
              "      <td>dear intp    enjoyed  conversation  other   es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ENTJ</td>\n",
              "      <td>50</td>\n",
              "      <td>youre firedthats another silly misconception t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-924dce18-c411-483c-9ba6-2f82ac9f8c61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-924dce18-c411-483c-9ba6-2f82ac9f8c61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-924dce18-c411-483c-9ba6-2f82ac9f8c61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "posts = np.array(data['Posts'])\n",
        "posts.astype(np.dtype('str'))\n",
        "data['Posts']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQyZBoCT66EC",
        "outputId": "0e9a1052-56ac-4ab2-b8e8-66a3c5d7e9af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         intj moments    sportscenter    plays    pra...\n",
              "1        finding  lack    these posts very alarmingsex...\n",
              "2       good       course  which    know thats  blessi...\n",
              "3       dear intp    enjoyed  conversation  other   es...\n",
              "4       youre firedthats another silly misconception t...\n",
              "                              ...                        \n",
              "7582     just because  always think  cats   doms  some...\n",
              "7583    soif this thread already exists someplace else...\n",
              "7584     many questions when   these things   would ta...\n",
              "7585      very conflicted right  when  comes  wanting ...\n",
              "7586      been  long since  have been  personalitycafe...\n",
              "Name: Posts, Length: 7587, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['type'].unique().shape[0] # 16 different personalities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CUp7x7l0hpQ",
        "outputId": "5bf4aaa0-9b9b-433b-9d51-a77a5eb84f72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-ap7objCsnq",
        "outputId": "5ea1f269-8973-4b48-9e49-50f8d227dd9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0          0\n",
              "type                0\n",
              "Number of posts     0\n",
              "Posts              42\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "JV_A0KidCul0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 1 : 16 class classification"
      ],
      "metadata": {
        "id": "CBXGUIEn1BlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data['Posts']"
      ],
      "metadata": {
        "id": "bM84fUjK5nym"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(data['type'])"
      ],
      "metadata": {
        "id": "VoFIUc3J1ZSo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_-HMBGa5a4S",
        "outputId": "5731da20-ffeb-4a10-d768-4d035e9a3e62"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = texts.astype('string')"
      ],
      "metadata": {
        "id": "zpJIHIS1B_lW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.3)"
      ],
      "metadata": {
        "id": "PRiqZVAH5hdi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts[:254])\n",
        "tokenizer.fit_on_texts(train_texts[256:])"
      ],
      "metadata": {
        "id": "xbQy2mvn5xYp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)"
      ],
      "metadata": {
        "id": "jom_Nh7k55Pk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PMIModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word_counter = None\n",
        "        self.pair_counter = None\n",
        "\n",
        "    def get_pair_id(self, word0, word1):\n",
        "        pair_id = tuple(sorted([word0, word1]))\n",
        "        return pair_id\n",
        "\n",
        "    def fit(self, sequences, window_size):\n",
        "\n",
        "        self.word_counter = Counter()\n",
        "        self.pair_counter = Counter()\n",
        "        num_windows = 0\n",
        "        for sequence in tqdm(sequences):\n",
        "            for offset in range(len(sequence) - window_size):\n",
        "                window = sequence[offset:offset + window_size]\n",
        "                num_windows += 1\n",
        "                for i, word0 in enumerate(window):\n",
        "                    self.word_counter[word0] += 1\n",
        "                    for j, word1 in enumerate(window[i + 1:]):\n",
        "                        pair_id = self.get_pair_id(word0, word1)\n",
        "                        self.pair_counter[pair_id] += 1\n",
        "\n",
        "        for word, count in self.word_counter.items():\n",
        "            self.word_counter[word] = count / num_windows\n",
        "        for pair_id, count in self.pair_counter.items():\n",
        "            self.pair_counter[pair_id] = count / num_windows\n",
        "\n",
        "    def transform(self, word0, word1):\n",
        "        prob_a = self.word_counter[word0]\n",
        "        prob_b = self.word_counter[word1]\n",
        "        pair_id = self.get_pair_id(word0, word1)\n",
        "        prob_pair = self.pair_counter[pair_id]\n",
        "\n",
        "        if prob_a == 0 or prob_b == 0 or prob_pair == 0:\n",
        "            return 0\n",
        "\n",
        "        pmi = np.log(prob_pair / (prob_a * prob_b))\n",
        "        # print(word0, word1, pmi)\n",
        "        pmi = np.maximum(pmi, 0.0)\n",
        "        # print(pmi)\n",
        "        return pmi"
      ],
      "metadata": {
        "id": "IvuxFtzz6Rbg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_word_graph(num_words, pmi_model, embedding_size):\n",
        "    x = tf.Variable(tf.random.truncated_normal([num_words, embedding_size], stddev=1 / np.sqrt(embedding_size)),\n",
        "                    dtype=tf.float32)\n",
        "    edges = []\n",
        "    edge_weight = []\n",
        "    for (word0, word1) in pmi_model.pair_counter.keys():\n",
        "        pmi = pmi_model.transform(word0, word1)\n",
        "        if pmi > 0:\n",
        "            edges.append([word0, word1])\n",
        "            edge_weight.append(pmi)\n",
        "            edges.append([word1, word0])\n",
        "            edge_weight.append(pmi)\n",
        "    edge_index = np.array(edges).T\n",
        "    return tfg.Graph(x=x, edge_index=edge_index, edge_weight=edge_weight)"
      ],
      "metadata": {
        "id": "dLvrOi5B4QTb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_combined_graph(word_graph, sequences, embedding_size):\n",
        "    num_words = word_graph.num_nodes\n",
        "    x = tf.zeros([len(sequences), embedding_size], dtype=tf.float32)\n",
        "    edges = []\n",
        "    edge_weight = []\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        doc_node_index = num_words + i\n",
        "        for word in sequence:\n",
        "            edges.append([doc_node_index, word])  # only directed edge\n",
        "            edge_weight.append(1.0)  # use BOW instaead of TF-IDF\n",
        "\n",
        "    edge_index = np.array(edges).T\n",
        "    x = tf.concat([word_graph.x, x], axis=0)\n",
        "    edge_index = np.concatenate([word_graph.edge_index, edge_index], axis=1)\n",
        "    edge_weight = np.concatenate([word_graph.edge_weight, edge_weight], axis=0)\n",
        "    return tfg.Graph(x=x, edge_index=edge_index, edge_weight=edge_weight)"
      ],
      "metadata": {
        "id": "ss6Wx4yw4Stt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pmi_cache_path = \"cached_pmi_model.p\"\n",
        "if os.path.exists(pmi_cache_path):\n",
        "    with open(pmi_cache_path, \"rb\") as f:\n",
        "        pmi_model = pickle.load(f)\n",
        "else:\n",
        "    pmi_model = PMIModel()\n",
        "    pmi_model.fit(train_sequences, window_size=6)\n",
        "    with open(pmi_cache_path, \"wb\") as f:\n",
        "        pickle.dump(pmi_model, f)\n",
        "\n",
        "embedding_size = 150\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "word_graph = build_word_graph(num_words, pmi_model, embedding_size)\n",
        "train_combined_graph = build_combined_graph(word_graph, train_sequences, embedding_size)\n",
        "test_combined_graph = build_combined_graph(word_graph, test_sequences, embedding_size)\n",
        "\n",
        "print(word_graph)\n",
        "print(train_combined_graph)\n",
        "print(test_combined_graph)\n",
        "\n",
        "num_classes = 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C1dplKZ4Vnj",
        "outputId": "ecdedb1d-50e6-4e02-fb83-7aa3aea94497"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Shape: x => (166465, 150)\tedge_index => (2, 8549996)\ty => None\n",
            "Graph Shape: x => (171746, 150)\tedge_index => (2, 11296098)\ty => None\n",
            "Graph Shape: x => (168729, 150)\tedge_index => (2, 9645728)\ty => None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_combined_graph)\n",
        "print(test_combined_graph)"
      ],
      "metadata": {
        "id": "n7EdD-TdWhmp",
        "outputId": "bdfadc6d-8c43-48af-eef0-fa8810a4daa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Shape: x => (171746, 150)\tedge_index => (2, 11296098)\ty => None\n",
            "Graph Shape: x => (168729, 150)\tedge_index => (2, 9645728)\ty => None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.gcn0 = tfg.layers.GCN(32, activation=tf.nn.relu)\n",
        "        self.gcn1 = tfg.layers.GCN(32,activation = tf.nn.relu)\n",
        "        self.gcn2 = tfg.layers.GCN(64,activation = tf.nn.relu)\n",
        "        self.gcn3 = tfg.layers.GCN(num_classes)\n",
        "        self.dropout = keras.layers.Dropout(0.5)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None, cache=None):\n",
        "        x, edge_index, edge_weight = inputs\n",
        "        h = self.gcn0([x, edge_index, edge_weight], cache=cache)\n",
        "        h = self.dropout(h, training=training);\n",
        "        h = self.gcn1([h, edge_index, edge_weight],cache=cache)\n",
        "        h = self.dropout(h, training=training);\n",
        "        h = self.gcn2([h, edge_index, edge_weight],cache=cache)\n",
        "        h = self.gcn3([h, edge_index, edge_weight], cache=cache)\n",
        "        return h"
      ],
      "metadata": {
        "id": "lbFPPM6k4ZmB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCNModel()\n",
        "model.gcn0.cache_normed_edge(train_combined_graph)\n",
        "model.gcn0.cache_normed_edge(test_combined_graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYl7plHU-cQp",
        "outputId": "0e6b4ae3-e480-45ab-b6d1-d8ba476c9e07"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tf_geometric/layers/conv/gcn.py:79: DeprecationWarning: 'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\n",
            "  warnings.warn(\"'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\", DeprecationWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/tf_geometric/layers/conv/gcn.py:79: DeprecationWarning: 'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\n",
            "  warnings.warn(\"'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\", DeprecationWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf_utils.function\n",
        "def forward(graph, training=False):\n",
        "    logits = model([graph.x, graph.edge_index, graph.edge_weight], cache=graph.cache, training=training)\n",
        "    logits = logits[num_words:]\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "tcIsXtoZ4dJA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(logits, labels):\n",
        "    losses = tf.nn.softmax_cross_entropy_with_logits(\n",
        "        logits=logits,\n",
        "        labels=tf.one_hot(labels, depth=num_classes)\n",
        "    )\n",
        "    # print(\"Transformed labels\", tf.one_hot(labels, depth=num_classes)[0])\n",
        "    mean_loss = tf.reduce_mean(losses)\n",
        "    return mean_loss"
      ],
      "metadata": {
        "id": "WPNkzHyb4eop"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=0.05)"
      ],
      "metadata": {
        "id": "YJ3BYYJp4gA0",
        "outputId": "0d700885-e63d-4175-ba0a-44dffc6faa43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(1000):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = forward(train_combined_graph, training=True)\n",
        "        # print(\"logits\" ,logits[0],\"Shape\",logits[0].shape)\n",
        "        mean_loss = compute_loss(logits, train_labels)\n",
        "\n",
        "    vars = tape.watched_variables()\n",
        "    grads = tape.gradient(mean_loss, vars)\n",
        "    optimizer.apply_gradients(zip(grads, vars))\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        # train accuracytf.one_hot(labels, depth=num_classes)\n",
        "        preds = tf.argmax(logits, axis=-1)\n",
        "        corrects = tf.cast(tf.equal(preds, train_labels), tf.float32)\n",
        "        train_accuracy = tf.reduce_mean(corrects)\n",
        "\n",
        "        logits = forward(test_combined_graph)\n",
        "        preds = tf.argmax(logits, axis=-1)\n",
        "        corrects = tf.cast(tf.equal(preds, test_labels), tf.float32)\n",
        "        accuracy = tf.reduce_mean(corrects)\n",
        "        print(\"step = {}\\tloss = {}\\ttrain_accuracy = {}\\ttest_accuracy = {}\".format(step, mean_loss, train_accuracy,accuracy))"
      ],
      "metadata": {
        "id": "oPEiI4jF7tQk",
        "outputId": "29e0b0b8-82d1-4f8f-d35f-83b25a7031ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 0\tloss = 2.0382018089294434\ttrain_accuracy = 0.2927475869655609\ttest_accuracy = 0.1590106040239334\n",
            "step = 10\tloss = 2.3622095584869385\ttrain_accuracy = 0.2291232794523239\ttest_accuracy = 0.21378092467784882\n",
            "step = 20\tloss = 2.188244581222534\ttrain_accuracy = 0.2474910020828247\ttest_accuracy = 0.22305653989315033\n",
            "step = 30\tloss = 2.1507599353790283\ttrain_accuracy = 0.24199962615966797\ttest_accuracy = 0.22084805369377136\n",
            "step = 40\tloss = 2.133229970932007\ttrain_accuracy = 0.2637757956981659\ttest_accuracy = 0.21908126771450043\n",
            "step = 50\tloss = 2.12540864944458\ttrain_accuracy = 0.260556697845459\ttest_accuracy = 0.2186395823955536\n",
            "step = 60\tloss = 2.1151161193847656\ttrain_accuracy = 0.26964589953422546\ttest_accuracy = 0.2186395823955536\n",
            "step = 70\tloss = 2.1087772846221924\ttrain_accuracy = 0.2681310474872589\ttest_accuracy = 0.21775618195533752\n",
            "step = 80\tloss = 2.0987906455993652\ttrain_accuracy = 0.2762734293937683\ttest_accuracy = 0.2173144817352295\n",
            "step = 90\tloss = 2.0886826515197754\ttrain_accuracy = 0.2783563733100891\ttest_accuracy = 0.21775618195533752\n",
            "step = 100\tloss = 2.085427761077881\ttrain_accuracy = 0.2741904854774475\ttest_accuracy = 0.2186395823955536\n",
            "step = 110\tloss = 2.096656322479248\ttrain_accuracy = 0.2770308554172516\ttest_accuracy = 0.21643109619617462\n",
            "step = 120\tloss = 2.0805094242095947\ttrain_accuracy = 0.27968189120292664\ttest_accuracy = 0.21687279641628265\n",
            "step = 130\tloss = 2.0856058597564697\ttrain_accuracy = 0.2783563733100891\ttest_accuracy = 0.21643109619617462\n",
            "step = 140\tloss = 2.0678727626800537\ttrain_accuracy = 0.27873510122299194\ttest_accuracy = 0.2159893959760666\n",
            "step = 150\tloss = 2.077521800994873\ttrain_accuracy = 0.28081801533699036\ttest_accuracy = 0.21643109619617462\n",
            "step = 160\tloss = 2.084578275680542\ttrain_accuracy = 0.28176480531692505\ttest_accuracy = 0.21554769575595856\n",
            "step = 170\tloss = 2.0753984451293945\ttrain_accuracy = 0.289339154958725\ttest_accuracy = 0.21422260999679565\n",
            "step = 180\tloss = 2.072998285293579\ttrain_accuracy = 0.2855519652366638\ttest_accuracy = 0.21422260999679565\n",
            "step = 190\tloss = 2.0668582916259766\ttrain_accuracy = 0.28365838527679443\ttest_accuracy = 0.21510601043701172\n",
            "step = 200\tloss = 2.06892466545105\ttrain_accuracy = 0.2864987552165985\ttest_accuracy = 0.21554769575595856\n",
            "step = 210\tloss = 2.063079833984375\ttrain_accuracy = 0.2842264771461487\ttest_accuracy = 0.21554769575595856\n",
            "step = 220\tloss = 2.06722354888916\ttrain_accuracy = 0.28271159529685974\ttest_accuracy = 0.2159893959760666\n",
            "step = 230\tloss = 2.0742006301879883\ttrain_accuracy = 0.28271159529685974\ttest_accuracy = 0.21687279641628265\n",
            "step = 240\tloss = 2.0720722675323486\ttrain_accuracy = 0.2825222611427307\ttest_accuracy = 0.2173144817352295\n",
            "step = 250\tloss = 2.060704231262207\ttrain_accuracy = 0.2846051752567291\ttest_accuracy = 0.21687279641628265\n",
            "step = 260\tloss = 2.063880443572998\ttrain_accuracy = 0.2830903232097626\ttest_accuracy = 0.2159893959760666\n",
            "step = 270\tloss = 2.065272808074951\ttrain_accuracy = 0.2863094210624695\ttest_accuracy = 0.21643109619617462\n",
            "step = 280\tloss = 2.0633604526519775\ttrain_accuracy = 0.2834690511226654\ttest_accuracy = 0.21510601043701172\n",
            "step = 290\tloss = 2.064347982406616\ttrain_accuracy = 0.2866881191730499\ttest_accuracy = 0.21643109619617462\n",
            "step = 300\tloss = 2.066909074783325\ttrain_accuracy = 0.283279687166214\ttest_accuracy = 0.2146643102169037\n",
            "step = 310\tloss = 2.0625038146972656\ttrain_accuracy = 0.28593069314956665\ttest_accuracy = 0.21510601043701172\n",
            "step = 320\tloss = 2.0643982887268066\ttrain_accuracy = 0.283279687166214\ttest_accuracy = 0.21554769575595856\n",
            "step = 330\tloss = 2.0624241828918457\ttrain_accuracy = 0.2802499532699585\ttest_accuracy = 0.21554769575595856\n",
            "step = 340\tloss = 2.0708374977111816\ttrain_accuracy = 0.283279687166214\ttest_accuracy = 0.21687279641628265\n",
            "step = 350\tloss = 2.064286708831787\ttrain_accuracy = 0.28498390316963196\ttest_accuracy = 0.21643109619617462\n",
            "step = 360\tloss = 2.0561704635620117\ttrain_accuracy = 0.2872562110424042\ttest_accuracy = 0.2159893959760666\n",
            "step = 370\tloss = 2.0596468448638916\ttrain_accuracy = 0.28990721702575684\ttest_accuracy = 0.21510601043701172\n",
            "step = 380\tloss = 2.0692665576934814\ttrain_accuracy = 0.2855519652366638\ttest_accuracy = 0.21510601043701172\n",
            "step = 390\tloss = 2.061025619506836\ttrain_accuracy = 0.283279687166214\ttest_accuracy = 0.2159893959760666\n",
            "step = 400\tloss = 2.0656535625457764\ttrain_accuracy = 0.2804393172264099\ttest_accuracy = 0.2159893959760666\n",
            "step = 410\tloss = 2.0562782287597656\ttrain_accuracy = 0.2834690511226654\ttest_accuracy = 0.21554769575595856\n",
            "step = 420\tloss = 2.0522360801696777\ttrain_accuracy = 0.289528489112854\ttest_accuracy = 0.21554769575595856\n",
            "step = 430\tloss = 2.0580995082855225\ttrain_accuracy = 0.2866881191730499\ttest_accuracy = 0.2159893959760666\n",
            "step = 440\tloss = 2.0499696731567383\ttrain_accuracy = 0.29293695092201233\ttest_accuracy = 0.21643109619617462\n",
            "step = 450\tloss = 2.0643537044525146\ttrain_accuracy = 0.2851732671260834\ttest_accuracy = 0.21510601043701172\n",
            "step = 460\tloss = 2.060821294784546\ttrain_accuracy = 0.281575471162796\ttest_accuracy = 0.21510601043701172\n",
            "step = 470\tloss = 2.0630035400390625\ttrain_accuracy = 0.28365838527679443\ttest_accuracy = 0.21554769575595856\n",
            "step = 480\tloss = 2.0547573566436768\ttrain_accuracy = 0.28706684708595276\ttest_accuracy = 0.21510601043701172\n",
            "step = 490\tloss = 2.0438179969787598\ttrain_accuracy = 0.2918007969856262\ttest_accuracy = 0.21510601043701172\n",
            "step = 500\tloss = 2.055363178253174\ttrain_accuracy = 0.28403711318969727\ttest_accuracy = 0.21510601043701172\n",
            "step = 510\tloss = 2.0522546768188477\ttrain_accuracy = 0.28896042704582214\ttest_accuracy = 0.2159893959760666\n",
            "step = 520\tloss = 2.0493197441101074\ttrain_accuracy = 0.2874455451965332\ttest_accuracy = 0.21554769575595856\n",
            "step = 530\tloss = 2.0525856018066406\ttrain_accuracy = 0.2916114330291748\ttest_accuracy = 0.21245582401752472\n",
            "step = 540\tloss = 2.0527822971343994\ttrain_accuracy = 0.2885816991329193\ttest_accuracy = 0.21378092467784882\n",
            "step = 550\tloss = 2.059190034866333\ttrain_accuracy = 0.28574132919311523\ttest_accuracy = 0.2159893959760666\n",
            "step = 560\tloss = 2.056241273880005\ttrain_accuracy = 0.28498390316963196\ttest_accuracy = 0.2159893959760666\n",
            "step = 570\tloss = 2.0552971363067627\ttrain_accuracy = 0.2851732671260834\ttest_accuracy = 0.2159893959760666\n",
            "step = 580\tloss = 2.0526070594787598\ttrain_accuracy = 0.2866881191730499\ttest_accuracy = 0.2173144817352295\n",
            "step = 590\tloss = 2.049565315246582\ttrain_accuracy = 0.2885816991329193\ttest_accuracy = 0.2159893959760666\n",
            "step = 600\tloss = 2.0472960472106934\ttrain_accuracy = 0.28914979100227356\ttest_accuracy = 0.21510601043701172\n",
            "step = 610\tloss = 2.0435616970062256\ttrain_accuracy = 0.28914979100227356\ttest_accuracy = 0.21510601043701172\n",
            "step = 620\tloss = 2.0498459339141846\ttrain_accuracy = 0.28820300102233887\ttest_accuracy = 0.21510601043701172\n",
            "step = 630\tloss = 2.0424060821533203\ttrain_accuracy = 0.29009658098220825\ttest_accuracy = 0.2146643102169037\n",
            "step = 640\tloss = 2.0487444400787354\ttrain_accuracy = 0.2883923351764679\ttest_accuracy = 0.2146643102169037\n",
            "step = 650\tloss = 2.0510404109954834\ttrain_accuracy = 0.2853626310825348\ttest_accuracy = 0.21422260999679565\n",
            "step = 660\tloss = 2.0482630729675293\ttrain_accuracy = 0.28271159529685974\ttest_accuracy = 0.2146643102169037\n",
            "step = 670\tloss = 2.0567121505737305\ttrain_accuracy = 0.2830903232097626\ttest_accuracy = 0.21510601043701172\n",
            "step = 680\tloss = 2.0416910648345947\ttrain_accuracy = 0.29085400700569153\ttest_accuracy = 0.21510601043701172\n",
            "step = 690\tloss = 2.049567222595215\ttrain_accuracy = 0.2887710630893707\ttest_accuracy = 0.2159893959760666\n",
            "step = 700\tloss = 2.0533289909362793\ttrain_accuracy = 0.2883923351764679\ttest_accuracy = 0.21643109619617462\n",
            "step = 710\tloss = 2.047511339187622\ttrain_accuracy = 0.2864987552165985\ttest_accuracy = 0.21554769575595856\n",
            "step = 720\tloss = 2.0449469089508057\ttrain_accuracy = 0.28914979100227356\ttest_accuracy = 0.21510601043701172\n",
            "step = 730\tloss = 2.0675694942474365\ttrain_accuracy = 0.28365838527679443\ttest_accuracy = 0.21510601043701172\n",
            "step = 740\tloss = 2.0486085414886475\ttrain_accuracy = 0.2866881191730499\ttest_accuracy = 0.21510601043701172\n",
            "step = 750\tloss = 2.0477678775787354\ttrain_accuracy = 0.28914979100227356\ttest_accuracy = 0.2146643102169037\n",
            "step = 760\tloss = 2.0522403717041016\ttrain_accuracy = 0.283279687166214\ttest_accuracy = 0.21333922445774078\n",
            "step = 770\tloss = 2.050473690032959\ttrain_accuracy = 0.2914220690727234\ttest_accuracy = 0.21510601043701172\n",
            "step = 780\tloss = 2.0419671535491943\ttrain_accuracy = 0.29217952489852905\ttest_accuracy = 0.21422260999679565\n",
            "step = 790\tloss = 2.049917221069336\ttrain_accuracy = 0.2874455451965332\ttest_accuracy = 0.20892226696014404\n",
            "step = 800\tloss = 2.045548677444458\ttrain_accuracy = 0.2944518029689789\ttest_accuracy = 0.20273850858211517\n",
            "step = 810\tloss = 2.0492589473724365\ttrain_accuracy = 0.29009658098220825\ttest_accuracy = 0.2146643102169037\n",
            "step = 820\tloss = 2.043583869934082\ttrain_accuracy = 0.2876349091529846\ttest_accuracy = 0.21422260999679565\n",
            "step = 830\tloss = 2.04781436920166\ttrain_accuracy = 0.29009658098220825\ttest_accuracy = 0.21510601043701172\n",
            "step = 840\tloss = 2.048872709274292\ttrain_accuracy = 0.28801363706588745\ttest_accuracy = 0.21554769575595856\n",
            "step = 850\tloss = 2.0444509983062744\ttrain_accuracy = 0.29123273491859436\ttest_accuracy = 0.21201413869857788\n",
            "step = 860\tloss = 2.050487995147705\ttrain_accuracy = 0.2876349091529846\ttest_accuracy = 0.21643109619617462\n",
            "step = 870\tloss = 2.030773162841797\ttrain_accuracy = 0.2953985929489136\ttest_accuracy = 0.21378092467784882\n",
            "step = 880\tloss = 2.0397517681121826\ttrain_accuracy = 0.2948305308818817\ttest_accuracy = 0.208480566740036\n",
            "step = 890\tloss = 2.037480354309082\ttrain_accuracy = 0.28990721702575684\ttest_accuracy = 0.2146643102169037\n",
            "step = 900\tloss = 2.0510640144348145\ttrain_accuracy = 0.289339154958725\ttest_accuracy = 0.21554769575595856\n",
            "step = 910\tloss = 2.035743236541748\ttrain_accuracy = 0.2876349091529846\ttest_accuracy = 0.2146643102169037\n",
            "step = 920\tloss = 2.0421199798583984\ttrain_accuracy = 0.28498390316963196\ttest_accuracy = 0.20759716629981995\n",
            "step = 930\tloss = 2.031560182571411\ttrain_accuracy = 0.2967241108417511\ttest_accuracy = 0.2146643102169037\n",
            "step = 940\tloss = 2.043318510055542\ttrain_accuracy = 0.29085400700569153\ttest_accuracy = 0.20627208054065704\n",
            "step = 950\tloss = 2.044285297393799\ttrain_accuracy = 0.2925582230091095\ttest_accuracy = 0.208480566740036\n",
            "step = 960\tloss = 2.042855978012085\ttrain_accuracy = 0.2897178530693054\ttest_accuracy = 0.20141342282295227\n",
            "step = 970\tloss = 2.038536310195923\ttrain_accuracy = 0.2918007969856262\ttest_accuracy = 0.20803886651992798\n",
            "step = 980\tloss = 2.046403408050537\ttrain_accuracy = 0.28896042704582214\ttest_accuracy = 0.2018551230430603\n",
            "step = 990\tloss = 2.0383718013763428\ttrain_accuracy = 0.28687748312950134\ttest_accuracy = 0.21333922445774078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['type']"
      ],
      "metadata": {
        "id": "_amCWm7U20nP",
        "outputId": "8ebe7a32-9f0a-43d7-ce86-0ecb7d64f7bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       INFJ\n",
              "1       ENTP\n",
              "2       INTP\n",
              "3       INTJ\n",
              "4       ENTJ\n",
              "        ... \n",
              "7582    ISFP\n",
              "7583    ENFP\n",
              "7584    INTP\n",
              "7585    INFP\n",
              "7586    INFP\n",
              "Name: type, Length: 7545, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vDiNDOAW6iMs"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}